# streamlit_app.py
import streamlit as st

from retrieval import load_resources, hybrid_search, parse_filter_hints


# -------------------------
# PAGE CONFIG
# -------------------------
st.set_page_config(page_title="Vietnamese Law Hybrid Search", page_icon="âš–ï¸")

st.title("âš–ï¸ Vietnamese Law Hybrid Search")
st.caption("Há»i Ä‘Ã¡p luáº­t Viá»‡t Nam (Hybrid Search: Dense + Sparse + RRF).")


# -------------------------
# LOAD RESOURCES
# -------------------------
@st.cache_resource
def get_resources():
    return load_resources()

try:
    r = get_resources()
except FileNotFoundError:
    st.error("âš ï¸ KhÃ´ng tÃ¬m tháº¥y `tfidf_model.pkl`. HÃ£y cháº¡y ingest trÆ°á»›c: `python preprocess_word.py`.")
    st.stop()
except Exception as e:
    # Qdrant locked or other issues
    msg = str(e)
    if "already accessed" in msg or "locked" in msg.lower():
        st.error(
            "âš ï¸ Qdrant Local Ä‘ang bá»‹ khÃ³a bá»Ÿi tiáº¿n trÃ¬nh khÃ¡c.\n\n"
            "ğŸ‘‰ HÃ£y táº¯t cÃ¡c tab/app Ä‘ang dÃ¹ng Qdrant hoáº·c vÃ o **Manage App â†’ Reboot App**."
        )
        st.stop()
    st.error(f"âš ï¸ Lá»—i load resources: {e}")
    st.stop()


# -------------------------
# SIDEBAR
# -------------------------
with st.sidebar:
    st.header("Settings")
    top_k = st.slider("Sá»‘ káº¿t quáº£", min_value=1, max_value=20, value=5)

    show_score = st.checkbox("Hiá»‡n score", value=False)
    show_full_default = st.checkbox("Má»Ÿ sáºµn ná»™i dung Ä‘áº§y Ä‘á»§", value=False)

    st.markdown("---")
    if st.button("XÃ³a lá»‹ch sá»­ chat"):
        st.session_state.messages = [
            {"role": "assistant", "content": "Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» phÃ¡p luáº­t Viá»‡t Nam hÃ´m nay?"}
        ]
        st.rerun()


# -------------------------
# INIT CHAT HISTORY
# -------------------------
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp gÃ¬ cho báº¡n vá» phÃ¡p luáº­t Viá»‡t Nam hÃ´m nay?"}
    ]


# -------------------------
# RENDER HISTORY
# -------------------------
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])


# -------------------------
# CHAT INPUT
# -------------------------
prompt = st.chat_input("Nháº­p cÃ¢u há»i cá»§a báº¡n á»Ÿ Ä‘Ã¢y...")
if prompt:
    # user message
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # search
    try:
        results, q_filter = hybrid_search(prompt, top_k, r)

        article_num, clause_num, point_id = parse_filter_hints(prompt)
        filter_badge = []
        if article_num is not None:
            filter_badge.append(f"Äiá»u {article_num}")
        if clause_num is not None:
            filter_badge.append(f"Khoáº£n {clause_num}")
        if point_id is not None:
            filter_badge.append(f"Äiá»ƒm {point_id}")

        # build assistant response (markdown)
        if not results.points:
            response_md = "KhÃ´ng tÃ¬m tháº¥y káº¿t quáº£ phÃ¹ há»£p."
            if filter_badge:
                response_md += "\n\n*(ÄÃ£ Ã¡p dá»¥ng lá»c: " + ", ".join(filter_badge) + ")*"
        else:
            response_md = f"**TÃ¬m tháº¥y {len(results.points)} káº¿t quáº£.**"
            if filter_badge:
                response_md += "\n\n*(ÄÃ£ Ã¡p dá»¥ng lá»c: " + ", ".join(filter_badge) + ")*"

            # Render as rich UI in assistant message area
            with st.chat_message("assistant"):
                st.markdown(response_md)

                for i, p in enumerate(results.points, 1):
                    payload = p.payload or {}

                    doc_id = payload.get("doc_id", "N/A")
                    chapter = payload.get("chapter", "")
                    chapter_title = payload.get("chapter_title", "")

                    article = payload.get("article", "N/A")   # Ä‘Ã£ lÃ  "Äiá»u 10. ..."
                    clause = payload.get("clause", None)      # "1." hoáº·c "Khoáº£n 1."
                    point = payload.get("point", None)        # "a)"
                    text = payload.get("text", "")

                    # Title line
                    title_parts = [article]
                    if clause:
                        title_parts.append(f"Khoáº£n {clause}".replace("Khoáº£n Khoáº£n", "Khoáº£n").strip())
                    if point:
                        title_parts.append(f"Äiá»ƒm {point}".replace("Äiá»ƒm Äiá»ƒm", "Äiá»ƒm").strip())
                    title = " â€¢ ".join([t for t in title_parts if t])

                    st.markdown(f"### {i}. {title}")

                    meta_line = " | ".join([x for x in [doc_id, (chapter + " " + chapter_title).strip()] if x.strip()])
                    if meta_line:
                        st.caption(meta_line)

                    if show_score:
                        st.caption(f"score: {p.score:.4f}")

                    # snippet
                    snippet = text[:350] + ("..." if len(text) > 350 else "")
                    if snippet:
                        st.markdown(f"> {snippet}")

                    # full content
                    if show_full_default:
                        st.markdown(text)
                    else:
                        with st.expander("Xem Ä‘áº§y Ä‘á»§"):
                            st.markdown(text)

                    st.divider()

            # also store a compact text version in history (so rerun still shows something)
            # (Keep it short to avoid re-render duplication)
            st.session_state.messages.append({"role": "assistant", "content": response_md})
            st.stop()

    except Exception as e:
        response_md = f"ÄÃ£ xáº£y ra lá»—i: {e}\n\nHÃ£y kiá»ƒm tra log."
        with st.chat_message("assistant"):
            st.markdown(response_md)
        st.session_state.messages.append({"role": "assistant", "content": response_md})
        st.stop()

    # If no results path reached here (rare), render response_md
    with st.chat_message("assistant"):
        st.markdown(response_md)
    st.session_state.messages.append({"role": "assistant", "content": response_md})
